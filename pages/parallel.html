<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<title>GPU n-body Simulation</title>
		<meta name="author" content="Paulius Bieksa">
		<meta name="description" content="Parallel implementation of an n-body siimulation. Uses CUDA to run code on the GPU.">
		<!--Import Google Icon Font-->
		<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
		<!--Import materialize.css-->
		<link type="text/css" rel="stylesheet" href="../styles/materialize.min.css"  media="screen,projection"/>
		<link rel="stylesheet" href="../styles/main.css">
		<!--Let browser know website is optimized for mobile-->
		<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	</head>
	<body>
		<div class="container">
			<div class="row center article_title">
				<h5 id="page_title">GPU n-body Simulation</h5>
				<!-- Asociated tags are generated here by pages_common.js -->
				<p id="date_stamp"><time datetime="2018-12">December 2018</time></p>
			</div>
			
			<div class="row left article">
				<!-- Empty column to center the article -->
				<div class="col s0 m1 l2"></div>
				<article class="col s12 m10 l8">
					<img src="../assets/images/cuda_simulation_400_cropped.gif">
					<h5>Introduction</h5>
					<p>Software optimisation is a field unto itself. There are many ways 
						to approach this problems in these field and all of them require 
						deep understanding of the code being optimised and the hardware
						the software is running on.
					</p>
					<p>This project attempts to speed up an <a class="explanation"
						href="https://en.wikipedia.org/wiki/N-body_simulation" 
						target="_blank"><abbr title="In physics and astronomy, an N-body simulation is a simulation of a dynamical system of particles, usually under the influence of physical forces">
						n-body problem</abbr></a> simulation algorithm by parallelising it. 
						The n-body problem is the problem of predicting the individual motions 
						of a group of celestial objects interacting with each other gravitationally. 
						The problem requires calculating how each body affects each other body being 
						simulated, and has complexity of O(n<sup>2</sup>). The simulation considers 
						each body as a point particle (a body with no spacial extension), and uses 
						Newtonâ€™s laws of motion to calculate the movement of the bodies in 2D space.
					</p>
					<p>There were two approaches taken - CPU parallelisation using OpenMp and GPU parallelisation using CUDA.
						The GPU approach was the focus of this project.
					</p>
					<h5>The algorithm</h5>
					<p>
						The n-body simulation requires each body to calculate forces exerted upon it by each other body.
						This is perfect for parallelisation because each body can be simulated on a separate thread.
						While on the CPU this could cause some <a class="explanation"
						href="https://en.wikipedia.org/wiki/Race_condition" target="_blank"
						<abbr title="A race condition or race hazard is the behavior of an electronics, software, or other system where the system's substantive behavior is dependent on the sequence or timing of other uncontrollable events. It becomes a bug when one or more of the possible behaviors is undesirable.">
						data races</abbr></a> if not considered carefuly, the usual approach for parallel GPU programming 
						separates input and output data, which makes it much easier to protect against data races.
					</p>
					<p>
						The algorithm itself is fairly simple:
						<ol type="I">
							<li>Convert the current state of all particles into a single float array</li>
							<li>Send the converted state to the GPU</li>
							<li><i>The next steps are done concurently on the GPU</i>
								<ol type="i">
									<li>Calculate the force exerted by each other particle based on their current state</li>
									<li>Store the forces to the correct GPU memory location</li>
								</ol>
							</li>
							<li>Send the calculated figures back to the main memory</li>
							<li>Convert the forces from float array to vectors</li>
							<li>Calculate the physics step with the forces calculated on the GPU</li>
						</ol>
						After some experimentation it was found that it is faster to perform the last step sequentially on the CPU. Since the 
						physics step has O(n) complexity it can be done quite quickly on the CPU.
					</p>
					<h5>Results</h5>
					<p>
						The GPU implementation achieved some very good results. An almost six-fold speedup was achieved when simulating 4000 bodies, 
						whith a trend towards more speedup when simulating more bodies. It is likely that a higher speedup would be achieved simulating 
						more bodies, but due to limited time for testing this was not verified.
					</p>
					<p>
						The results for the OpenMP simulation were a bit more complex. Some speedup was gained on some machines while on others 
						the simulation ran slower. Particularly interesting was a revelation that adding a wait command (~100)ms improved overall performance 
						on some Windows machines. There was no CPU temperature difference or declocking to explain it and the exact reason for 
						this strange behavior was not found in the time allotted.
					</p>
					<div class="footnote_links">
						<a target="_blank" href="https://github.com/PauliusBieksa/n-Body_simulation">Git repository</a> | 
						<a target="_blank" href="../Assets/PDFs/CPS_CW2_Report.pdf">Full report</a></p>
					</div>
				</article>
			</div>
		</div>
		
		
		<!--JavaScript at end of body for optimized loading-->
		<script type="text/javascript" src="../scripts/materialize.min.js"></script>
		<script type="text/javascript" src="../assets/data/index.json"></script>
		<script type="text/javascript" src="../scripts/pages_common.js"></script>
	</body>
</html>
