<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<title>Fractal visualizer</title>
		<meta name="author" content="Paulius Bieksa">
		<meta name="description" content="A 3D fractal music visualizer for live input.">
		<!--Import Google Icon Font-->
		<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
		<!--Import materialize.css-->
		<link type="text/css" rel="stylesheet" href="../styles/materialize.min.css"  media="screen,projection"/>
		<link rel="stylesheet" href="../styles/main.css">
		<link href="https://fonts.googleapis.com/css?family=Varela+Round&display=swap" rel="stylesheet">
		<!--Let browser know website is optimized for mobile-->
		<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	</head>
	<body>
		<div class="container">
			<div class="row center article_title">
				<h5 id="page_title">Fractal visualizer</h5>
				<!-- Asociated tags are generated here by pages_common.js -->
				<p id="date_stamp"><time datetime="2019-04">April 2019</time></p>
			</div>
			
			<div class="row left article">
				<!-- Empty column to center the article -->
				<div class="col s0 m1 l2"></div>
				<!---->
				<article class="col s12 m10 l8">
					<div class="video_wrapper">
						<iframe width="100%" src="https://www.youtube-nocookie.com/embed/he9CQAuUC-Y?rel=0" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					</div>
					
					<h5>Introduction</h5>
					<p>This is my Honours project for my Games Development degree. It visualizes live audio input using 3D fractals for the 
						visuals. I undertook this project because I wanted to explore a possibility of a performance tool for live music and 
						at the same time work on a graphically focused project.
					</p>
					
					<h5>How it works</h5>
					<p>The application has three main logical components: audio handler, fractal renderer, and main controller. The main 
						controller controls the flow of the application. The application works somewhat similarly to a game as it is focused 
						on rendering frames and performing all its calculations once per frame. The audio handler deals with audio input and 
						analysis. It returns various properties of the input audio. The fractal renderer receives the audio properties and 
						uses them as seeds for fractal rendering. The rendering is done entirely in the fractal shader by using ray-marching.
					</p>
					
					<h5>Results</h5>
					<p>The application renders a fractal that reacts to music being played. The application struggles with chords and multiple 
						notes at the same time however. I believe this is due to my approach in analyzing audio. When taking advantage of the strengths 
						of the application, a suitably impressive output can be achieved.
					</p>
					
					<img src="../assets/images/visualizer/fractal_guitar_reduced.gif">
					
					<div class="footnote_links">
						<a target="_blank" href="https://github.com/PauliusBieksa/3D_Fractal_visualizer">Git repository</a> | 
						<a target="_blank" href="../assets/PDFs/Dissertation.pdf">Full report</a>
					</div>
				</article>
			</div>
		</div>
		
		
		<!--JavaScript at end of body for optimized loading-->
		<script type="text/javascript" src="../scripts/materialize.min.js"></script>
		<script type="text/javascript" src="../assets/data/index.json"></script>
		<script type="text/javascript" src="../scripts/pages_common.js"></script>
	</body>
</html>
